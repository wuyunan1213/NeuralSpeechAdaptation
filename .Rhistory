View(n_cor)
max(n_cor$acc)
View(n_cor)
n_cor[n_cor$acc, 'Subject']
n_cor[n_cor$acc, Subject]
n_cor[n_cor$acc, 1]
n_cor[n_cor$acc > 0.6,]
n_cor[n_cor$acc > 0.6, 'Subject']
rm(list = ls())
library(dplyr)
library(reshape2)
library(plyr)
library(ggplot2)
library(gplots)
library(tidyverse)
source('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/BasicFunctionsSD.R')
setwd('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/NoiseBEERPIER')
###read directly from the dataset saved in the NoiseCueWeights analysis
ddd <- read.csv("data.csv")
colnames(ddd)[3] <- 'Condition'
levels(ddd$Condition) <- c('Noise', 'Clear')
###change the block number a little bit
ddd$Block[ddd$Block == 4 | ddd$Block == 9] <- 'Canonical'
ddd$Block[ddd$Block == 5 | ddd$Block == 10] <- 'Reverse'
cols <- c('Subject', 'votlevel', 'Block', 'f0level', 'Condition')
ddd[cols] <- lapply(ddd[cols], factor)
###procef0levele.block. is identical to block except with votlevelific names
ddd %>%
subset(StimType == 'test') %>%
ddply(., ~Subject+Condition+Block+f0level+votlevel, summarise, perPier = sum(response == "m")/length(response)) -> dw
View(dw)
dw <- dw[dw$Subject %in% c(14, 16, 17, 19, 23, 25, 44, 46, 47, 48, 50, 51, 52, 57, 60, 62, 64, 65, 66, 67, 8, 9),]
dw %>%
ddply(., ~Condition+Block+f0level+votlevel, summarise, ave = mean(perPier), sd = sd(perPier), n = length(perPier), se = sd/sqrt(n), lower = ave-se, upper = ave+se) -> summ
#png('clearVOT.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Clear' & f0level == 4) %>%
LinePlot(., 'Block', 'ave', 'votlevel', 'lower', 'upper', 'VOT', 'Short', 'Long', '%P responses', xlabName = 'Clear Speech', FontSize = fs, DimLevel1Color =  'blue', DimLevel2Color = 'green')
###line plot in clear
fs = 10
#png('clearVOT.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Clear' & f0level == 4) %>%
LinePlot(., 'Block', 'ave', 'votlevel', 'lower', 'upper', 'VOT', 'Short', 'Long', '%P responses', xlabName = 'Clear Speech', FontSize = fs, DimLevel1Color =  'blue', DimLevel2Color = 'green')
#png('clearF0.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Clear' & votlevel == 4) %>%
LinePlot(., 'Block', 'ave', 'f0level', 'lower', 'upper', 'F0', 'Low', 'High', '%P responses', xlabName = 'Clear Speech', FontSize = fs)
#png('NoiseVOT.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Noise' & f0level == 4) %>%
LinePlot(., 'Block', 'ave', 'votlevel', 'lower', 'upper', 'VOT', 'Short', 'Long', '%P responses', xlabName = 'Noise Masking', FontSize = fs, DimLevel1Color =  'blue', DimLevel2Color = 'green')
#png('NoiseF0.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Noise' & votlevel == 4) %>%
LinePlot(., 'Block', 'ave', 'f0level', 'lower', 'upper', 'F0', 'Low', 'High', '%P responses', xlabName = 'Noise Masking', FontSize = fs)
rm(list = ls())
library(dplyr)
library(reshape2)
library(plyr)
library(ggplot2)
library(gplots)
library(tidyverse)
source('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/BasicFunctionsSD.R')
setwd("/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/NoiseBEERPIER")
###change the block number a little bit
ddd <- read.csv("data.csv")
colnames(ddd)[3] <- 'Condition'
levels(ddd$Condition) <- c('Noise', 'Clear')
###change the block number a little bit
ddd$Block[ddd$Block == 4 | ddd$Block == 9] <- 'Canonical'
ddd$Block[ddd$Block == 5 | ddd$Block == 10] <- 'Reverse'
###do not change the vot and f0 levels to factor yet
cols <- c('Subject', 'Block', 'Condition')
ddd[cols] <- lapply(ddd[cols], factor)
ddd %>%
subset(Block %in% c('Canonical', 'Reverse') & StimType == 'exposure' & Condition == 'Clear') %>%
exposure_accuracy(., dim1 = votlevel, response = response) %>%
ddply(., ~Subject+Condition+Block, summarise, acc = mean(Acc)) ->clear_accuracy
ddd %>%
subset(Block %in% c('Canonical', 'Reverse') & StimType == 'exposure' & Condition == 'Noise') %>%
exposure_accuracy(., dim1 = f0level, response = response) %>%
ddply(., ~Subject+Condition+Block, summarise, acc = mean(Acc)) ->nv_accuracy
ddd %>%
subset(StimType == 'test') %>%
ddply(., ~Subject+Condition+Block+votlevel+f0level, summarise, perPier = sum(response == 'm')/length(response)) -> test
test %>%
subset(votlevel == 4) %>%
ddply(., ~Subject+Condition+Block, summarise, f0_diff= diff(perPier)) ->test_f0
test %>%
subset(f0level == 4) %>%
ddply(., ~Subject+Condition+Block, summarise, vot_diff = diff(perPier)) ->test_vot
cw <- read.csv('CueWeightMatrix.csv')
merge(rbind(clear_accuracy, nv_accuracy), merge(test_f0, test_vot)) %>%
subset(Block == 'Reverse') %>%
join(., cw) -> all
rm(list = ls())
library(dplyr)
library(reshape2)
library(plyr)
library(ggplot2)
library(gplots)
library(tidyverse)
source('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/BasicFunctionsSD.R')
setwd('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/NoiseBEERPIER')
###read directly from the dataset saved in the NoiseCueWeights analysis
ddd <- read.csv("data.csv")
colnames(ddd)[3] <- 'Condition'
levels(ddd$Condition) <- c('Noise', 'Clear')
###change the block number a little bit
ddd$Block[ddd$Block == 4 | ddd$Block == 9] <- 'Canonical'
ddd$Block[ddd$Block == 5 | ddd$Block == 10] <- 'Reverse'
cols <- c('Subject', 'votlevel', 'Block', 'f0level', 'Condition')
ddd[cols] <- lapply(ddd[cols], factor)
rm(list = ls())
library(dplyr)
library(reshape2)
library(plyr)
library(ggplot2)
library(gplots)
library(tidyverse)
source('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/BasicFunctionsSD.R')
setwd("/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/VocodingSETSAT")
ddd <- read.csv("4DownWeight_Data_final.csv")
###change the block number a little bit
ddd$Block[ddd$Block == 3] <- 1
ddd$Block[ddd$Block == 4] <- 2
cols <- c('Subject', 'spec', 'Block', 'duration', 'VocoderChannel')
ddd[cols] <- lapply(ddd[cols], factor)
###procedure.block. is identical to block except with specific names
ddd %>%
select(Subject, VocoderChannel, Block, StimType, Procedure.Block., StimSubType, duration, spec, response=ImageDisplay2.RESP) %>%
subset(StimType == 'test') %>%
ddply(., ~Subject+VocoderChannel+Procedure.Block.+Block+duration+spec, summarise, perSAT = sum(response == "m")/length(response)) -> dw
dw %>%
ddply(., ~VocoderChannel+Procedure.Block.+duration+spec, summarise, ave = mean(perSAT), sd = sd(perSAT), n = length(perSAT), se = sd/sqrt(n), lower = ave-se, upper = ave+se) -> summ
###line plot in clear
fs = 10
png('clearSQ.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(VocoderChannel == 0 & duration == 4) %>%
LinePlot(., 'Procedure.Block.', 'ave', 'spec', 'lower', 'upper', 'SQ', 'SET-like', 'SAT-like', '%AE responses', xlabName = 'Clear Speech', FontSize = fs, DimLevel1Color =  'blue', DimLevel2Color = 'green')
dev.off()
png('clearDU.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(VocoderChannel == 0 & spec == 4) %>%
LinePlot(., 'Procedure.Block.', 'ave', 'duration', 'lower', 'upper', 'Duration', 'Short', 'Long', '%AE responses', xlabName = 'Clear Speech', FontSize = fs)
dev.off()
png('NVSQ.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(VocoderChannel == 4 & duration == 4) %>%
LinePlot(., 'Procedure.Block.', 'ave', 'spec', 'lower', 'upper', 'SQ', 'SET-like', 'SAT-like', '%AE responses', xlabName = 'Noise-vocoded', FontSize = fs, DimLevel1Color =  'blue', DimLevel2Color = 'green')
dev.off()
png('NVDU.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(VocoderChannel == 4 & spec == 4) %>%
LinePlot(., 'Procedure.Block.', 'ave', 'duration', 'lower', 'upper', 'Duration', 'Short', 'Long', '%AE responses', xlabName = 'Noise-vocoded', FontSize = fs)
dev.off()
#rm(list = ls())
library(dplyr)
library(reshape2)
library(plyr)
library(ggplot2)
library(gplots)
library(tidyverse)
source('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/BasicFunctionsSD.R')
setwd('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/NoiseBEERPIER')
###read directly from the dataset saved in the NoiseCueWeights analysis
ddd <- read.csv("data.csv")
colnames(ddd)[3] <- 'Condition'
levels(ddd$Condition) <- c('Noise', 'Clear')
###change the block number a little bit
ddd$Block[ddd$Block == 4 | ddd$Block == 9] <- 'Canonical'
ddd$Block[ddd$Block == 5 | ddd$Block == 10] <- 'Reverse'
cols <- c('Subject', 'votlevel', 'Block', 'f0level', 'Condition')
ddd[cols] <- lapply(ddd[cols], factor)
rm(list = ls())
library(dplyr)
library(reshape2)
library(plyr)
library(ggplot2)
library(gplots)
library(tidyverse)
source('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/BasicFunctionsSD.R')
setwd("/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/VocodingSETSAT")
ddd <- read.csv("4DownWeight_Data_final.csv")
###change the block number a little bit
ddd$Block[ddd$Block == 3] <- 1
ddd$Block[ddd$Block == 4] <- 2
cols <- c('Subject', 'spec', 'Block', 'duration', 'VocoderChannel')
ddd[cols] <- lapply(ddd[cols], factor)
###procedure.block. is identical to block except with specific names
ddd %>%
select(Subject, VocoderChannel, Block, StimType, Procedure.Block., StimSubType, duration, spec, response=ImageDisplay2.RESP) %>%
subset(StimType == 'test') %>%
ddply(., ~Subject+VocoderChannel+Procedure.Block.+Block+duration+spec, summarise, perSAT = sum(response == "m")/length(response)) -> dw
dw %>%
ddply(., ~VocoderChannel+Procedure.Block.+duration+spec, summarise, ave = mean(perSAT), sd = sd(perSAT), n = length(perSAT), se = sd/sqrt(n), lower = ave-se, upper = ave+se) -> summ
###line plot in clear
fs = 10
png('clearSQ.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(VocoderChannel == 0 & duration == 4) %>%
LinePlot(., 'Procedure.Block.', 'ave', 'spec', 'lower', 'upper', 'SQ', 'SET-like', 'SAT-like', '%AE responses', xlabName = 'Clear Speech', FontSize = fs, DimLevel1Color =  'blue', DimLevel2Color = 'green')
dev.off()
png('clearDU.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(VocoderChannel == 0 & spec == 4) %>%
LinePlot(., 'Procedure.Block.', 'ave', 'duration', 'lower', 'upper', 'Duration', 'Short', 'Long', '%AE responses', xlabName = 'Clear Speech', FontSize = fs)
dev.off()
png('NVSQ.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(VocoderChannel == 4 & duration == 4) %>%
LinePlot(., 'Procedure.Block.', 'ave', 'spec', 'lower', 'upper', 'SQ', 'SET-like', 'SAT-like', '%AE responses', xlabName = 'Noise-vocoded', FontSize = fs, DimLevel1Color =  'blue', DimLevel2Color = 'green')
dev.off()
png('NVDU.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(VocoderChannel == 4 & spec == 4) %>%
LinePlot(., 'Procedure.Block.', 'ave', 'duration', 'lower', 'upper', 'Duration', 'Short', 'Long', '%AE responses', xlabName = 'Noise-vocoded', FontSize = fs)
dev.off()
rm(list = ls())
library(dplyr)
library(reshape2)
library(plyr)
library(ggplot2)
library(gplots)
library(tidyverse)
source('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/BasicFunctionsSD.R')
setwd("/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/NoiseBEERPIER")
###change the block number a little bit
ddd <- read.csv("data.csv")
colnames(ddd)[3] <- 'Condition'
levels(ddd$Condition) <- c('Noise', 'Clear')
###change the block number a little bit
ddd$Block[ddd$Block == 4 | ddd$Block == 9] <- 'Canonical'
ddd$Block[ddd$Block == 5 | ddd$Block == 10] <- 'Reverse'
###do not change the vot and f0 levels to factor yet
cols <- c('Subject', 'Block', 'Condition')
ddd[cols] <- lapply(ddd[cols], factor)
ddd %>%
subset(Block %in% c('Canonical', 'Reverse') & StimType == 'exposure' & Condition == 'Clear') %>%
exposure_accuracy(., dim1 = votlevel, response = response) %>%
ddply(., ~Subject+Condition+Block, summarise, acc = mean(Acc)) ->clear_accuracy
ddd %>%
subset(Block %in% c('Canonical', 'Reverse') & StimType == 'exposure' & Condition == 'Noise') %>%
exposure_accuracy(., dim1 = f0level, response = response) %>%
ddply(., ~Subject+Condition+Block, summarise, acc = mean(Acc)) ->nv_accuracy
ddd %>%
subset(StimType == 'test') %>%
ddply(., ~Subject+Condition+Block+votlevel+f0level, summarise, perPier = sum(response == 'm')/length(response)) -> test
test %>%
subset(votlevel == 4) %>%
ddply(., ~Subject+Condition+Block, summarise, f0_diff= diff(perPier)) ->test_f0
test %>%
subset(f0level == 4) %>%
ddply(., ~Subject+Condition+Block, summarise, vot_diff = diff(perPier)) ->test_vot
cw <- read.csv('CueWeightMatrix.csv')
merge(rbind(clear_accuracy, nv_accuracy), merge(test_f0, test_vot)) %>%
subset(Block == 'Reverse') %>%
join(., cw) -> all
###because of outliers and small sample size, we don't see a good pattern
###First look at correlation between baseline weights and accuracy
fs = 10
clear_cor <- all[all$Condition == 'Clear',]
n_cor <- all[all$Condition == 'Noise',]
#rm(list = ls())
library(dplyr)
library(reshape2)
library(plyr)
library(ggplot2)
library(gplots)
library(tidyverse)
source('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/BasicFunctionsSD.R')
setwd('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/NoiseBEERPIER')
###read directly from the dataset saved in the NoiseCueWeights analysis
ddd <- read.csv("data.csv")
colnames(ddd)[3] <- 'Condition'
levels(ddd$Condition) <- c('Noise', 'Clear')
###change the block number a little bit
ddd$Block[ddd$Block == 4 | ddd$Block == 9] <- 'Canonical'
ddd$Block[ddd$Block == 5 | ddd$Block == 10] <- 'Reverse'
cols <- c('Subject', 'votlevel', 'Block', 'f0level', 'Condition')
ddd[cols] <- lapply(ddd[cols], factor)
###procef0levele.block. is identical to block except with votlevelific names
ddd %>%
subset(StimType == 'test') %>%
ddply(., ~Subject+Condition+Block+f0level+votlevel, summarise, perPier = sum(response == "m")/length(response)) -> dw
View(n_cor)
n_cor[n_cor$acc > 65, 'Subject']
n_cor[n_cor$acc > 65,]
n_cor[n_cor$acc > 0.65,]
dw <- dw[dw$Subject %in% n_cor[n_cor$acc > 0.65, 'Subject'],]
View(dw)
View(dw)
length(levels(dw$Subject))
length(levels(factor(dw$Subject)))
dw %>%
ddply(., ~Condition+Block+f0level+votlevel, summarise, ave = mean(perPier), sd = sd(perPier), n = length(perPier), se = sd/sqrt(n), lower = ave-se, upper = ave+se) -> summ
#png('clearVOT.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Clear' & f0level == 4) %>%
LinePlot(., 'Block', 'ave', 'votlevel', 'lower', 'upper', 'VOT', 'Short', 'Long', '%P responses', xlabName = 'Clear Speech', FontSize = fs, DimLevel1Color =  'blue', DimLevel2Color = 'green')
#png('clearF0.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Clear' & votlevel == 4) %>%
LinePlot(., 'Block', 'ave', 'f0level', 'lower', 'upper', 'F0', 'Low', 'High', '%P responses', xlabName = 'Clear Speech', FontSize = fs)
#png('NoiseVOT.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Noise' & f0level == 4) %>%
LinePlot(., 'Block', 'ave', 'votlevel', 'lower', 'upper', 'VOT', 'Short', 'Long', '%P responses', xlabName = 'Noise Masking', FontSize = fs, DimLevel1Color =  'blue', DimLevel2Color = 'green')
#png('NoiseF0.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Noise' & votlevel == 4) %>%
LinePlot(., 'Block', 'ave', 'f0level', 'lower', 'upper', 'F0', 'Low', 'High', '%P responses', xlabName = 'Noise Masking', FontSize = fs)
###procef0levele.block. is identical to block except with votlevelific names
ddd %>%
subset(StimType == 'test') %>%
ddply(., ~Subject+Condition+Block+f0level+votlevel, summarise, perPier = sum(response == "m")/length(response)) -> dw
dw <- dw[dw$Subject %in% n_cor[n_cor$acc > 0.5, 'Subject'],]
dw %>%
ddply(., ~Condition+Block+f0level+votlevel, summarise, ave = mean(perPier), sd = sd(perPier), n = length(perPier), se = sd/sqrt(n), lower = ave-se, upper = ave+se) -> summ
#png('clearVOT.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Clear' & f0level == 4) %>%
LinePlot(., 'Block', 'ave', 'votlevel', 'lower', 'upper', 'VOT', 'Short', 'Long', '%P responses', xlabName = 'Clear Speech', FontSize = fs, DimLevel1Color =  'blue', DimLevel2Color = 'green')
#png('clearF0.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Clear' & votlevel == 4) %>%
LinePlot(., 'Block', 'ave', 'f0level', 'lower', 'upper', 'F0', 'Low', 'High', '%P responses', xlabName = 'Clear Speech', FontSize = fs)
#png('NoiseVOT.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Noise' & f0level == 4) %>%
LinePlot(., 'Block', 'ave', 'votlevel', 'lower', 'upper', 'VOT', 'Short', 'Long', '%P responses', xlabName = 'Noise Masking', FontSize = fs, DimLevel1Color =  'blue', DimLevel2Color = 'green')
#png('NoiseF0.png', units = 'in', width = 4, height = 4, res = 500)
summ %>%
subset(Condition == 'Noise' & votlevel == 4) %>%
LinePlot(., 'Block', 'ave', 'f0level', 'lower', 'upper', 'F0', 'Low', 'High', '%P responses', xlabName = 'Noise Masking', FontSize = fs)
cor.test(n_cor$acc, n_cor$vot_diff)
cor.test(n_cor$F0, n_cor$vot_diff)
cor.test(clear_cor$acc, clear_cor$f0_diff)
cor.test(clear_cor$acc, clear_cor$f0_diff)
cor.test(clear_cor$vot, clear_cor$f0_diff)
View(n_cor)
mean(n_cor$acc)
mean(clear_cor$acc)
rm(list = ls())
library(dplyr)
library(reshape2)
library(plyr)
library(ggplot2)
library(gplots)
library(tidyverse)
source('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/BasicFunctionsSD.R')
setwd("/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/NoiseBEERPIER")
###change the block number a little bit
ddd <- read.csv("data.csv")
colnames(ddd)[3] <- 'Condition'
levels(ddd$Condition) <- c('Noise', 'Clear')
###change the block number a little bit
ddd$Block[ddd$Block == 4 | ddd$Block == 9] <- 'Canonical'
ddd$Block[ddd$Block == 5 | ddd$Block == 10] <- 'Reverse'
###do not change the vot and f0 levels to factor yet
cols <- c('Subject', 'Block', 'Condition')
ddd[cols] <- lapply(ddd[cols], factor)
ddd %>%
subset(Block %in% c('Canonical', 'Reverse') & StimType == 'exposure' & Condition == 'Clear') %>%
exposure_accuracy(., dim1 = votlevel, response = response) %>%
ddply(., ~Subject+Condition+Block, summarise, acc = mean(Acc)) ->clear_accuracy
ddd %>%
subset(Block %in% c('Canonical', 'Reverse') & StimType == 'exposure' & Condition == 'Noise') %>%
exposure_accuracy(., dim1 = f0level, response = response) %>%
ddply(., ~Subject+Condition+Block, summarise, acc = mean(Acc)) ->nv_accuracy
ddd %>%
subset(StimType == 'test') %>%
ddply(., ~Subject+Condition+Block+votlevel+f0level, summarise, perPier = sum(response == 'm')/length(response)) -> test
test %>%
subset(votlevel == 4) %>%
ddply(., ~Subject+Condition+Block, summarise, f0_diff= diff(perPier)) ->test_f0
test %>%
subset(f0level == 4) %>%
ddply(., ~Subject+Condition+Block, summarise, vot_diff = diff(perPier)) ->test_vot
cw <- read.csv('CueWeightMatrix.csv')
merge(rbind(clear_accuracy, nv_accuracy), merge(test_f0, test_vot)) %>%
subset(Block == 'Reverse') %>%
join(., cw) -> all
###because of outliers and small sample size, we don't see a good pattern
###First look at correlation between baseline weights and accuracy
fs = 10
clear_cor <- all[all$Condition == 'Clear',]
n_cor <- all[all$Condition == 'Noise',]
mean(clear_cor$acc)
mean(n_cor$acc)
sd(n_cor$acc)
length(n_cor$acc)
sd(n_cor$acc)/sqrt(61)
sd(clear_cor$acc)/sqrt(61)
sd(clear_cor$acc)
rm(list = ls())
library(dplyr)
library(reshape2)
library(plyr)
library(ggplot2)
library(gplots)
library(tidyverse)
setwd('/Users/charleswu/Google Drive/HoltLab/CueWeighting/Modeling/Network/NeuralSpeechAdaptation')
grid <- read.csv('GRID.csv')
View(grid)
View(grid)
grid %>%
spread(Dimension1:Dimension2, Dimension, probability) -> melted_grid
grid %>%
spread(Dimension1:Dimension2, Dimension, probability)
grid %>%
spread(Dimension, probability, Dimension1:Dimension2)
?spread
grid %>%
spread(Dimension1:Dimension2, probability)
spread(grid, Dimension1:Dimension2, probability)
View(grid)
spread(grid, Dimension, Probabilit, Dimension1:Dimension2y)
spread(grid, Dimension1:Dimension2, Probability, Dimension)
spread(grid, Dimension1:Dimension2, Probability)
spread(grid, Dimension1, Probability)
spread(grid, c(Dimension1, Dimension2), Probability)
spread(grid, Dimension1, Dimension2, Probability)
spread(grid, Dimension1, Dimension2)
grid %>%
gather(Dimension1:Dimension2, Dimension, probability)
?gather
grid %>%
gather(Dimension, probability, Dimension1:Dimension2)
rm(list = ls())
library(dplyr)
library(reshape2)
library(plyr)
library(ggplot2)
library(gplots)
library(tidyverse)
source('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/BasicFunctionsSD.R')
setwd('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/NoiseBEERPIER')
ddd <- read.csv("BeerPier_Final.csv")
cols <- c('Subject', 'Block')
ddd[cols] <- lapply(ddd[cols], factor)
# In this chunk, we first set up the matrix containing all the cue weights for the two acoustic dimensions in the two conditions, clearn and noisy speech.
###because the data collection was not set up nicely and the response columns were scattered in different columns so I will write a function to deal with that
combine <- function(x){
b1 <- x[2] == 6
b2 <- x[2] == 7
b3 <- x[2] == 8
cdw1 <- x[2] == 9
cdw2 <- x[2] == 10
x[b1, 8] <-  x[b1, 9]
x[b2, 8] <-  x[b2, 9]
x[b3, 8] <-  x[b3, 9]
x[cdw1, 8] <-  x[cdw1, 10]
x[cdw2, 8] <-  x[cdw2, 11]
return(x)
}
###find the matrix with all condition, block and cue combinations
ddd %>%
select(Subject, Block, StimCategory, StimType, StimSubType, f0level, votlevel, responseNoise=ImageDisplay2.RESP, responseClear = ImageDisplay8.RESP, responseClearDw1 = ImageDisplay10.RESP, responseClearDw2 = ImageDisplay12.RESP) %>%
ddply(., ~Subject, combine) -> data
data <- data[,c(-9, -10, -11)]
colnames(data)[8] <- 'response'
###save data
# write.csv(data, 'Data.csv', row.names = FALSE)
data %>%
subset(StimType == 'exposure') %>%
subset(Block %in% c(1,2,3,6,7,8)) %>%
ddply(., ~Subject+StimCategory+f0level+votlevel, summarise, perPier = sum(response == "m")/length(response)) %>%
ddply(., ~Subject+StimCategory, function(x){CalculateCueWeights(x, perPier, votlevel, f0level)})-> cw
colnames(cw)[2:4] <- c('Condition','VOT', 'F0')
levels(cw$Condition) <- c('Noise', 'Clear')
cw$Condition <- factor(cw$Condition, ordered = TRUE)
CWmatrix <- gather(cw, Dimension, weight, VOT:F0)
# write.csv(cw, 'CueWeightMatrix.csv', row.names = FALSE)
data %>%
subset(StimType == 'exposure') %>%
subset(Block %in% c(1,2,3,6,7,8)) %>%
ddply(., ~Subject+StimCategory+f0level+votlevel, summarise, perPier = sum(response == "m")/length(response)) %>%
ddply(., ~StimCategory+f0level+votlevel, summarise, ave = mean(perPier)) -> meanResp
clear_hm <- subset(meanResp, StimCategory == 'clear')
nv_hm <- subset(meanResp, StimCategory == '0dB')
View(clear_hm)
rm(list = ls())
library(dplyr)
library(reshape2)
library(plyr)
library(ggplot2)
library(gplots)
library(tidyverse)
setwd('/Users/charleswu/Google Drive/HoltLab/CueWeighting/Modeling/Network/NeuralSpeechAdaptation')
grid <- read.csv('GRID.csv')
source('/Users/charleswu/Google Drive/CMUacademics/Research/Dissertation/SignalDistortion/BasicFunctionsSD.R')
rep(seq(1,7), 7)
rep(1:7, 7)
?seq
?rep
rep(1:7, times = 7)
rep(1:7, each = 7)
grid$Dimension1 <- rep(1:7, each = 7)
grid$Dimension2 <- rep(1:7, times = 7)
?plot_heatmap
View(plot_heatmap)
plot_heatmap(grid, Probability, Dimension1, Dimension2, 'Dimension 1', 'Dimension 2', 'Heatmap of model probabilities', 'BEER', 'PIER')
View(grid)
png('Model_heatmap.png', units = 'in', height = 4, width = 5, res = 500)
plot_heatmap(grid, Probability, Dimension1, Dimension2, 'Dimension 1', 'Dimension 2', 'Heatmap of model probabilities', 'BEER', 'PIER')
dev.off()
View(grid)
grid <- read.csv('GRID.csv')
View(grid)
